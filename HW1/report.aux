\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Algorithm}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces First 20 eigenvectors, using first 2000 training samples. They are aligned from left to right and top to down. They become dark after normalization. So in this figure, each value is multiplied by 10, i.e., each vector has norm of 100, instead of 1. }}{2}}
\newlabel{fig:eigen}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Reconstruction of digits. From left to right on each line, there are original digits, digits constructed by first 100 eigenvectors, digits constructed by first 200 eigenvectors, and digits constructed by first 600 eigenvectors. }}{2}}
\newlabel{fig:test}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparison on using different number of training samples. Testing on first 1000 testing set. Using first 200 eigen-vectors. K for K-nearest-neighbors is 1.}}{3}}
\newlabel{fig:dataset}{{3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison on using different number of eigenvectors. Testing on first 1000 testing set. Using first 1500 and 3000 training samples for each line. K for K-nearest-neighbors is 1.}}{3}}
\newlabel{fig:evec}{{4}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiments}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Data coordinates on first two basis in $E$ space. Using first 5000 training samples. Testing on first 1000 testing samples.}}{4}}
\newlabel{fig:twod}{{5}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{4}}
